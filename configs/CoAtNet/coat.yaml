depth_multiple: 1.0  # model depth multiple
width_multiple: 1.0  # layer channel multiple
backbone:
  # [from, number, module, args]
  [[-1, 1, ConvGE, [128, 3, 2]],  # Conv+BN+GELU
   [-1, 1, ConvGE, [128, 3, 1]],

    [-1, 1, CoAtNetMBConv, [128, 2]], # MBConv for CoAtNet
    [-1, 1, CoAtNetMBConv, [ 256, 2]],

   [-1, 1, CoAtNetTrans, [512, 2, [40,40]]], # Transformer for CoAtNet
   [-1, 1, CoAtNetTrans, [1024, 2, [20,20]]],
   [-1, 1, SPPF, [1024, 5]] #6
  ]

neck:
  [ [ -1, 1, SimConv, [ 256, 1, 1 ] ],
    [ -1, 1, Transpose, [ 256 ] ],
    [ [ -1, 4 ], 1, Concat, [ 1 ] ],  #768
    [ -1, 1, BepC3, [ 256, 12, "ConvWrapper" ] ],

    [ -1, 1, SimConv, [ 128, 1, 1 ] ],
    [ -1, 1, Transpose, [ 128 ] ],
    [ [ -1, 3 ], 1, Concat, [ 1 ] ],  #384
    [ -1, 1, BepC3, [ 128, 12, "ConvWrapper" ] ],   #out

    [ -1, 1, SimConv, [ 128, 3, 2 ] ],
    [ [ -1, 11 ], 1, Concat, [ 1 ] ],  # cat head P4
    [ -1, 1, BepC3, [ 256, 12, "ConvWrapper" ] ],  # 20 (P4/16-medium)

    [ -1, 1, SimConv, [ 256, 3, 2 ] ],
    [ [ -1, 7 ], 1, Concat, [ 1 ] ],  # cat head P5
    [ -1, 1, BepC3, [ 512, 12, "ConvWrapper" ] ] ]  # 23 (P5/32-large)

effidehead:
  [[14, 1, Head_layers, [128, 16]],
  [17, 1, Head_layers, [256, 16]],
  [20, 1, Head_layers, [512, 16]],
  [[21, 22, 23], 1, Out, []]]


